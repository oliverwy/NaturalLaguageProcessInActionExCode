{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d17217bd0d1dc75fc124b1baf47af913ae6650c56007a8cc26b22fb5e0065bb2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())\n",
    "import pandas as pd\n",
    "df=pd.read_csv('data/moviedialog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                          statement  \\\n",
       "0           0  you're asking me out. that's so cute. what's y...   \n",
       "1           1  no, no, it's my fault we didn't have a proper ...   \n",
       "2           2     gosh, if only we could find kat a boyfriend...   \n",
       "3           3                     c'esc ma tete. this is my head   \n",
       "4           4  how is our little find the wench a date plan p...   \n",
       "\n",
       "                                     reply  \n",
       "0                               forget it.  \n",
       "1                                 cameron.  \n",
       "2                let me see what i can do.  \n",
       "3   right. see? you're ready for the quiz.  \n",
       "4  well, there's someone i think might be   "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>statement</th>\n      <th>reply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>you're asking me out. that's so cute. what's y...</td>\n      <td>forget it.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>no, no, it's my fault we didn't have a proper ...</td>\n      <td>cameron.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>gosh, if only we could find kat a boyfriend...</td>\n      <td>let me see what i can do.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>c'esc ma tete. this is my head</td>\n      <td>right. see? you're ready for the quiz.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>how is our little find the wench a date plan p...</td>\n      <td>well, there's someone i think might be</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts,target_texts=[],[]\n",
    "input_vocabulary=set()\n",
    "output_vocabulary=set()\n",
    "start_token='\\t'\n",
    "stop_token='\\n'\n",
    "max_training_samples=min(25000,len(df)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_text,target_text in zip(df.statement,df.reply):\n",
    "    target_text=start_token+target_text+stop_token\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_vocabulary:\n",
    "            input_vocabulary.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in output_vocabulary:\n",
    "            output_vocabulary.add(char)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocabulary=sorted(input_vocabulary)\n",
    "output_vocabulary=sorted(output_vocabulary)\n",
    "input_vocab_size=len(input_vocabulary)\n",
    "output_vocab_size=len(output_vocabulary)\n",
    "max_encoder_seq_length=max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length=max([len(txt) for txt in target_texts])\n",
    "input_token_index=dict([(char,i ) for i,char in enumerate(input_vocabulary)])\n",
    "target_token_index=dict([(char,i) for i,char in enumerate(output_vocabulary)])\n",
    "reverse_input_token_index=dict([(i,char) for i,char in enumerate(input_vocabulary)])\n",
    "reverse_target_token_index=dict([(i,char) for i,char in enumerate(output_vocabulary)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "encoder_input_data=np.zeros((len(input_texts),max_encoder_seq_length,input_vocab_size),dtype='float32')\n",
    "decoder_input_data=np.zeros((len(input_texts),max_decoder_seq_length,output_vocab_size),dtype='float32')\n",
    "decoder_target_data=np.zeros((len(input_texts),max_decoder_seq_length,output_vocab_size),dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token_index[char]]=1\n",
    "    for yt,chart in enumerate(target_text):\n",
    "        decoder_input_data[i,yt,target_token_index[chart]]=1\n",
    "        if yt>0:\n",
    "            decoder_target_data[i,yt-1,target_token_index[chart]]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def onehot_encode_ger(sentence,char_indices,maxlen=40):\n",
    "    X=np.zeros((maxlen,len(char_indices.keys())))\n",
    "    for t,char in enumerate(sentence):\n",
    "        X[t,char_indices[char]]=1\n",
    "    return X\n",
    "    \n",
    "def onehot_encode_label(char,char_indices):\n",
    "    Y=np.zeros((len(char_indices)))\n",
    "    Y[char_indices[char]]=1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_generator(datastore,next_char,char_indices,batchsize=32,maxlen=40):\n",
    "    X,Y,Z=[],[],[]\n",
    "    while True:\n",
    "        for i in range(len(datastore)):\n",
    "            if (i % batchsize==0 and X and Y) or (i==len(datastore)):\n",
    "                X=np.reshape(X,(len(X),maxlen,len(char_indices)))\n",
    "                Y=np.reshape(Y,(len(Y),len(char_indices)))\n",
    "                yield X,Y\n",
    "                X,Y=[],[]\n",
    "            x=datastore[i]\n",
    "            y=next_chars[i]\n",
    "            x=onehot_encode_ger(x,char_indices,maxlen=maxlen)\n",
    "            y=onehot_encode_label(y,char_indices)   \n",
    "            X.append(x)\n",
    "            Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "227/227 [==============================] - 10s 38ms/step - loss: 1.1074 - acc: 0.0664 - val_loss: 1.0865 - val_acc: 0.0626\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 1.0683 - acc: 0.0632 - val_loss: 1.0863 - val_acc: 0.0661\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 1.0439 - acc: 0.0681 - val_loss: 1.0070 - val_acc: 0.0808\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 1.0212 - acc: 0.0728 - val_loss: 1.0251 - val_acc: 0.0778\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.9911 - acc: 0.0773 - val_loss: 1.0262 - val_acc: 0.0780\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.9767 - acc: 0.0806 - val_loss: 1.0173 - val_acc: 0.0803\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.9632 - acc: 0.0839 - val_loss: 0.9588 - val_acc: 0.0924\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.9594 - acc: 0.0866 - val_loss: 0.9412 - val_acc: 0.0962\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.9283 - acc: 0.0923 - val_loss: 0.9720 - val_acc: 0.0896\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.9162 - acc: 0.0952 - val_loss: 0.8393 - val_acc: 0.1197\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.8561 - acc: 0.1089 - val_loss: 0.8249 - val_acc: 0.1215\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.8300 - acc: 0.1127 - val_loss: 0.8240 - val_acc: 0.1217\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.8016 - acc: 0.1217 - val_loss: 0.8002 - val_acc: 0.1293\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.7791 - acc: 0.1255 - val_loss: 0.8466 - val_acc: 0.1192\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.7547 - acc: 0.1309 - val_loss: 0.7499 - val_acc: 0.1375\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.7394 - acc: 0.1351 - val_loss: 0.7987 - val_acc: 0.1290\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.7253 - acc: 0.1366 - val_loss: 0.7347 - val_acc: 0.1419\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.7100 - acc: 0.1396 - val_loss: 0.7176 - val_acc: 0.1464\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.7018 - acc: 0.1433 - val_loss: 0.7161 - val_acc: 0.1467\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6948 - acc: 0.1466 - val_loss: 0.7016 - val_acc: 0.1515\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6877 - acc: 0.1491 - val_loss: 0.7300 - val_acc: 0.1467\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6779 - acc: 0.1511 - val_loss: 0.6845 - val_acc: 0.1563\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6722 - acc: 0.1521 - val_loss: 0.6797 - val_acc: 0.1580\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6670 - acc: 0.1542 - val_loss: 0.6808 - val_acc: 0.1576\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6611 - acc: 0.1553 - val_loss: 0.6714 - val_acc: 0.1610\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6571 - acc: 0.1569 - val_loss: 0.6692 - val_acc: 0.1606\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6490 - acc: 0.1576 - val_loss: 0.6668 - val_acc: 0.1615\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6457 - acc: 0.1583 - val_loss: 0.6636 - val_acc: 0.1620\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6426 - acc: 0.1593 - val_loss: 0.6575 - val_acc: 0.1634\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6403 - acc: 0.1603 - val_loss: 0.6512 - val_acc: 0.1643\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6388 - acc: 0.1613 - val_loss: 0.6591 - val_acc: 0.1632\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6342 - acc: 0.1614 - val_loss: 0.6526 - val_acc: 0.1642\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6316 - acc: 0.1624 - val_loss: 0.6485 - val_acc: 0.1639\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6268 - acc: 0.1622 - val_loss: 0.6552 - val_acc: 0.1647\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6250 - acc: 0.1623 - val_loss: 0.6394 - val_acc: 0.1664\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6229 - acc: 0.1635 - val_loss: 0.6377 - val_acc: 0.1679\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6251 - acc: 0.1650 - val_loss: 0.6579 - val_acc: 0.1641\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6202 - acc: 0.1645 - val_loss: 0.6408 - val_acc: 0.1666\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6162 - acc: 0.1642 - val_loss: 0.6432 - val_acc: 0.1658\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6203 - acc: 0.1657 - val_loss: 0.6440 - val_acc: 0.1666\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6140 - acc: 0.1656 - val_loss: 0.6315 - val_acc: 0.1688\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6157 - acc: 0.1665 - val_loss: 0.6428 - val_acc: 0.1661\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6203 - acc: 0.1653 - val_loss: 0.6345 - val_acc: 0.1694\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6117 - acc: 0.1668 - val_loss: 0.6298 - val_acc: 0.1708\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6083 - acc: 0.1668 - val_loss: 0.6229 - val_acc: 0.1715\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6050 - acc: 0.1672 - val_loss: 0.6212 - val_acc: 0.1721\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6069 - acc: 0.1679 - val_loss: 0.6195 - val_acc: 0.1725\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.6073 - acc: 0.1690 - val_loss: 0.6265 - val_acc: 0.1711\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.6040 - acc: 0.1684 - val_loss: 0.6170 - val_acc: 0.1725\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.6003 - acc: 0.1687 - val_loss: 0.6212 - val_acc: 0.1721\n",
      "Epoch 51/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6040 - acc: 0.1699 - val_loss: 0.6155 - val_acc: 0.1727\n",
      "Epoch 52/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5982 - acc: 0.1692 - val_loss: 0.6149 - val_acc: 0.1737\n",
      "Epoch 53/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.6007 - acc: 0.1697 - val_loss: 0.6192 - val_acc: 0.1725\n",
      "Epoch 54/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.5976 - acc: 0.1704 - val_loss: 0.6152 - val_acc: 0.1737\n",
      "Epoch 55/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5951 - acc: 0.1704 - val_loss: 0.6172 - val_acc: 0.1733\n",
      "Epoch 56/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5998 - acc: 0.1718 - val_loss: 0.6132 - val_acc: 0.1737\n",
      "Epoch 57/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5954 - acc: 0.1708 - val_loss: 0.6159 - val_acc: 0.1731\n",
      "Epoch 58/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.5958 - acc: 0.1714 - val_loss: 0.6140 - val_acc: 0.1735\n",
      "Epoch 59/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.5917 - acc: 0.1707 - val_loss: 0.6091 - val_acc: 0.1740\n",
      "Epoch 60/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5965 - acc: 0.1718 - val_loss: 0.6078 - val_acc: 0.1746\n",
      "Epoch 61/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5939 - acc: 0.1724 - val_loss: 0.6097 - val_acc: 0.1750\n",
      "Epoch 62/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5898 - acc: 0.1705 - val_loss: 0.6045 - val_acc: 0.1747\n",
      "Epoch 63/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5923 - acc: 0.1721 - val_loss: 0.6071 - val_acc: 0.1753\n",
      "Epoch 64/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5929 - acc: 0.1725 - val_loss: 0.6140 - val_acc: 0.1735\n",
      "Epoch 65/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5852 - acc: 0.1708 - val_loss: 0.6054 - val_acc: 0.1755\n",
      "Epoch 66/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5867 - acc: 0.1712 - val_loss: 0.6036 - val_acc: 0.1756\n",
      "Epoch 67/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5857 - acc: 0.1720 - val_loss: 0.6084 - val_acc: 0.1744\n",
      "Epoch 68/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5884 - acc: 0.1721 - val_loss: 0.6014 - val_acc: 0.1761\n",
      "Epoch 69/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5916 - acc: 0.1730 - val_loss: 0.6064 - val_acc: 0.1753\n",
      "Epoch 70/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5849 - acc: 0.1723 - val_loss: 0.6016 - val_acc: 0.1765\n",
      "Epoch 71/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5832 - acc: 0.1720 - val_loss: 0.6019 - val_acc: 0.1763\n",
      "Epoch 72/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5856 - acc: 0.1732 - val_loss: 0.5995 - val_acc: 0.1765\n",
      "Epoch 73/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5863 - acc: 0.1734 - val_loss: 0.6066 - val_acc: 0.1753\n",
      "Epoch 74/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5839 - acc: 0.1729 - val_loss: 0.6096 - val_acc: 0.1748\n",
      "Epoch 75/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.5835 - acc: 0.1730 - val_loss: 0.6032 - val_acc: 0.1762\n",
      "Epoch 76/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5858 - acc: 0.1740 - val_loss: 0.6010 - val_acc: 0.1763\n",
      "Epoch 77/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5856 - acc: 0.1732 - val_loss: 0.6034 - val_acc: 0.1770\n",
      "Epoch 78/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5878 - acc: 0.1741 - val_loss: 0.6027 - val_acc: 0.1764\n",
      "Epoch 79/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.5827 - acc: 0.1729 - val_loss: 0.6007 - val_acc: 0.1763\n",
      "Epoch 80/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5848 - acc: 0.1735 - val_loss: 0.6012 - val_acc: 0.1762\n",
      "Epoch 81/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5847 - acc: 0.1747 - val_loss: 0.6014 - val_acc: 0.1768\n",
      "Epoch 82/100\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.5789 - acc: 0.1730 - val_loss: 0.5983 - val_acc: 0.1770\n",
      "Epoch 83/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5824 - acc: 0.1743 - val_loss: 0.6005 - val_acc: 0.1756\n",
      "Epoch 84/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5765 - acc: 0.1732 - val_loss: 0.5963 - val_acc: 0.1771\n",
      "Epoch 85/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5796 - acc: 0.1741 - val_loss: 0.6036 - val_acc: 0.1769\n",
      "Epoch 86/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5814 - acc: 0.1741 - val_loss: 0.5986 - val_acc: 0.1770\n",
      "Epoch 87/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5781 - acc: 0.1737 - val_loss: 0.6059 - val_acc: 0.1754\n",
      "Epoch 88/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5787 - acc: 0.1742 - val_loss: 0.5989 - val_acc: 0.1766\n",
      "Epoch 89/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5818 - acc: 0.1750 - val_loss: 0.5976 - val_acc: 0.1777\n",
      "Epoch 90/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5756 - acc: 0.1739 - val_loss: 0.5957 - val_acc: 0.1771\n",
      "Epoch 91/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5758 - acc: 0.1743 - val_loss: 0.5977 - val_acc: 0.1779\n",
      "Epoch 92/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5808 - acc: 0.1752 - val_loss: 0.6013 - val_acc: 0.1772\n",
      "Epoch 93/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5807 - acc: 0.1757 - val_loss: 0.5966 - val_acc: 0.1778\n",
      "Epoch 94/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5758 - acc: 0.1744 - val_loss: 0.5974 - val_acc: 0.1776\n",
      "Epoch 95/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5770 - acc: 0.1751 - val_loss: 0.5915 - val_acc: 0.1787\n",
      "Epoch 96/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5806 - acc: 0.1759 - val_loss: 0.5996 - val_acc: 0.1778\n",
      "Epoch 97/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5775 - acc: 0.1760 - val_loss: 0.5965 - val_acc: 0.1779\n",
      "Epoch 98/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5789 - acc: 0.1752 - val_loss: 0.6011 - val_acc: 0.1760\n",
      "Epoch 99/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5748 - acc: 0.1747 - val_loss: 0.5963 - val_acc: 0.1783\n",
      "Epoch 100/100\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.5743 - acc: 0.1755 - val_loss: 0.5990 - val_acc: 0.1784\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff58ca00100>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM,Dense,Input\n",
    "batch_size=256\n",
    "epochs=100\n",
    "num_neurons=256\n",
    "encoder_inputs=Input(shape=(None,input_vocab_size))\n",
    "encoder=LSTM(num_neurons,return_state=True)\n",
    "encoder_outputs,state_h,state_c=encoder(encoder_inputs)\n",
    "encoder_states=[state_h,state_c]\n",
    "\n",
    "decoder_inputs=Input(shape=(None,output_vocab_size))\n",
    "decoder_lstm=LSTM(num_neurons,return_sequences=True,return_state=True)\n",
    "decoder_outputs,_,_=decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense=Dense(output_vocab_size,activation='softmax')\n",
    "decoder_outputs=decoder_dense(decoder_outputs)\n",
    "model=Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics='acc')\n",
    "model.fit([encoder_input_data,decoder_input_data],decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model=Model(encoder_inputs,encoder_states)\n",
    "thought_input=[Input(shape=(num_neurons,)),Input(shape=(num_neurons,))]\n",
    "decoder_outputs,state_h,state_c=decoder_lstm(decoder_inputs,initial_state=thought_input)\n",
    "decoder_states=[state_h,state_c]\n",
    "decoder_outputs=decoder_dense(decoder_outputs)\n",
    "decoder_model=Model(inputs=[decoder_inputs]+thought_input,outputs=[decoder_outputs]+decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    thought=encoder_model.predict(input_seq)\n",
    "    target_seq=np.zeros((1,1,output_vocab_size))\n",
    "    target_seq[0,0,target_token_index[stop_token]]=1\n",
    "    stop_condition=False\n",
    "    generated_sequence=''\n",
    "    while not stop_condition:\n",
    "        output_tokens,h,c=decoder_model.predict([target_seq]+thought)\n",
    "        generated_token_idx=np.argmax(output_tokens[0,-1,:])\n",
    "        generated_char=reverse_target_token_index[generated_token_idx]\n",
    "        generated_sequence+=generated_char\n",
    "        if (generated_char==stop_token or len(generated_sequence)>max_decoder_seq_length):\n",
    "            stop_condition=True\n",
    "        target_seq=np.zeros((1,1,output_vocab_size))\n",
    "        target_seq[0,0,generated_token_idx]=1\n",
    "        thought=[h,c]\n",
    "    return generated_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(input_text):\n",
    "    input_seq=np.zeros((1,max_decoder_seq_length,input_vocab_size),dtype='float32')\n",
    "    for i ,char in enumerate(input_text):\n",
    "        input_seq[0,t,input_token_index[char]]=1\n",
    "    decode_sentence=decode_sequence(input_seq)\n",
    "    print('Bot reply:'+decode_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bot reply:it you want to see you to the proble the stare the stare the stare the stare the stare the stare the st\n"
     ]
    }
   ],
   "source": [
    "response(\"what is the interest?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bot reply:it you want to see you to the proble the stare the stare the stare the stare the stare the stare the st\n"
     ]
    }
   ],
   "source": [
    "response(\"why?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bot reply:it you want to see you to the proble the stare the stare the stare the stare the stare the stare the st\n"
     ]
    }
   ],
   "source": [
    "response(\"do you like coffee?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bot reply:it you want to see you to the proble the stare the stare the stare the stare the stare the stare the st\n"
     ]
    }
   ],
   "source": [
    "response(\"do you like football?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bot reply:it you want to see you to the proble the stare the stare the stare the stare the stare the stare the st\n"
     ]
    }
   ],
   "source": [
    "response(\"do you like me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}