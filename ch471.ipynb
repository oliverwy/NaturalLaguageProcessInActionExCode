{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nlpia.data.loaders import get_data\n",
    "pd.options.display.width=120\n",
    "sms=get_data('sms-spam')\n",
    "index=['sms{}{}'.format(i,'!'*j) for (i,j) in zip(range(len(sms)),sms.spam)]\n",
    "sms.index=index\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "tfidf=TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs=tfidf.fit_transform(raw_documents=sms.text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(tfidf_docs,sms.spam.values,test_size=0.2,random_state=271828)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda=LDA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=1)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "lda.fit(tfidf_docs,sms.spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['lda_spaminess']=lda.predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4837"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "(sms.spam==sms.lda_spaminess).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4837"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'准确率:0.96(+/-0.02)'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lda=LDA(n_components=1)\n",
    "scores=cross_val_score(lda,tfidf_docs,sms.spam,cv=10)\n",
    "\"准确率:{:.2f}(+/-{:.2f})\".format(scores.mean(),scores.std()*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9628099173553719"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "lda=LDA(n_components=1)\n",
    "lda.fit(x_train,y_train)\n",
    "lda.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=1)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "lda=LDA(n_components=1)\n",
    "lda.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia=LDiA(n_components=16,learning_method='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldia=ldia.fit(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldia_topic_vectors=ldia.transform(tfidf_docs)\n",
    "columns32=['topic{}'.format(i) for i in range(ldia.n_components)]\n",
    "ldia_topic_vectors=pd.DataFrame(ldia_topic_vectors,index=index,columns=columns32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            topic0    topic1    topic2    topic3    topic4    topic5    topic6    topic7    topic8    topic9  \\\n",
       "sms0      0.011198  0.011198  0.011198  0.011198  0.011198  0.356530  0.486695  0.011198  0.011198  0.011198   \n",
       "sms1      0.017648  0.017648  0.017648  0.017648  0.017648  0.017648  0.450083  0.017648  0.017648  0.017648   \n",
       "sms2!     0.009711  0.009711  0.009711  0.009711  0.009711  0.009711  0.009711  0.405771  0.009711  0.009711   \n",
       "sms3      0.122015  0.015563  0.015563  0.015563  0.015563  0.015563  0.660104  0.015563  0.015563  0.015563   \n",
       "sms4      0.014342  0.014342  0.014342  0.014342  0.014342  0.014342  0.014342  0.014342  0.014342  0.014342   \n",
       "...            ...       ...       ...       ...       ...       ...       ...       ...       ...       ...   \n",
       "sms4832!  0.009800  0.009800  0.009800  0.009800  0.009800  0.009800  0.009800  0.009800  0.009800  0.009800   \n",
       "sms4833   0.308414  0.016394  0.016394  0.016394  0.016394  0.016394  0.462073  0.016394  0.016394  0.016394   \n",
       "sms4834   0.013936  0.013936  0.013936  0.013936  0.013936  0.013936  0.013936  0.013936  0.013936  0.013936   \n",
       "sms4835   0.010823  0.010823  0.010823  0.010823  0.010823  0.010823  0.625231  0.010823  0.223250  0.010823   \n",
       "sms4836   0.019513  0.707307  0.019513  0.019513  0.019513  0.019513  0.019513  0.019513  0.019513  0.019513   \n",
       "\n",
       "           topic10   topic11   topic12   topic13   topic14   topic15  \n",
       "sms0      0.011198  0.011198  0.011198  0.011198  0.011198  0.011198  \n",
       "sms1      0.017648  0.302843  0.017648  0.017648  0.017648  0.017648  \n",
       "sms2!     0.009711  0.458278  0.009711  0.009711  0.009711  0.009711  \n",
       "sms3      0.015563  0.015563  0.015563  0.015563  0.015563  0.015563  \n",
       "sms4      0.472950  0.014342  0.326268  0.014342  0.014342  0.014342  \n",
       "...            ...       ...       ...       ...       ...       ...  \n",
       "sms4832!  0.009800  0.648584  0.009800  0.214221  0.009800  0.009800  \n",
       "sms4833   0.016394  0.016394  0.016394  0.016394  0.016394  0.016394  \n",
       "sms4834   0.322991  0.481907  0.013936  0.013936  0.013936  0.013936  \n",
       "sms4835   0.010823  0.010823  0.010823  0.010823  0.010823  0.010823  \n",
       "sms4836   0.019513  0.019513  0.019513  0.019513  0.019513  0.019513  \n",
       "\n",
       "[4837 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n      <th>topic14</th>\n      <th>topic15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sms0</th>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.356530</td>\n      <td>0.486695</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n      <td>0.011198</td>\n    </tr>\n    <tr>\n      <th>sms1</th>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.450083</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.302843</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n      <td>0.017648</td>\n    </tr>\n    <tr>\n      <th>sms2!</th>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.405771</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.458278</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n      <td>0.009711</td>\n    </tr>\n    <tr>\n      <th>sms3</th>\n      <td>0.122015</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.660104</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n      <td>0.015563</td>\n    </tr>\n    <tr>\n      <th>sms4</th>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.472950</td>\n      <td>0.014342</td>\n      <td>0.326268</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n      <td>0.014342</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>sms4832!</th>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n      <td>0.648584</td>\n      <td>0.009800</td>\n      <td>0.214221</td>\n      <td>0.009800</td>\n      <td>0.009800</td>\n    </tr>\n    <tr>\n      <th>sms4833</th>\n      <td>0.308414</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.462073</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n      <td>0.016394</td>\n    </tr>\n    <tr>\n      <th>sms4834</th>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.322991</td>\n      <td>0.481907</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n      <td>0.013936</td>\n    </tr>\n    <tr>\n      <th>sms4835</th>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.625231</td>\n      <td>0.010823</td>\n      <td>0.223250</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n      <td>0.010823</td>\n    </tr>\n    <tr>\n      <th>sms4836</th>\n      <td>0.019513</td>\n      <td>0.707307</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n      <td>0.019513</td>\n    </tr>\n  </tbody>\n</table>\n<p>4837 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "ldia_topic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(ldia_topic_vectors.values,sms.spam.values,test_size=0.2,random_state=271828)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=1, tol=1e-05)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "lda=LDA(n_components=1,solver='svd',store_covariance=False,shrinkage=None,priors=None,tol=0.00001)\n",
    "lda.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8801652892561983"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "lda.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=LDA(n_components=1,solver='svd',store_covariance=False,shrinkage=None,priors=None,tol=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'准确率:0.86(+/-0.02)'"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "scores=cross_val_score(lda,ldia_topic_vectors,sms.spam,cv=10)\n",
    "\"准确率:{:.2f}(+/-{:.2f})\".format(scores.mean(),scores.std()*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=16)\n",
    "pca=pca.fit(tfidf_docs)\n",
    "pca_topic_vectors=pca.transform(tfidf_docs)\n",
    "colums=['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca_topic_vectors=pd.DataFrame(pca_topic_vectors,columns=colums,index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         topic0    topic1    topic2    topic3    topic4    topic5    topic6    topic7    topic8    topic9   topic10  \\\n",
       "sms0   0.201169  0.002722  0.037228  0.010963 -0.019496 -0.053075  0.039710 -0.065104  0.011216 -0.081477  0.011095   \n",
       "sms1   0.404380 -0.093877 -0.077510  0.050900  0.099974  0.047044  0.022954  0.065189  0.022957 -0.023891 -0.003125   \n",
       "sms2! -0.030458 -0.048076  0.090197 -0.067028  0.090846 -0.043121 -0.000488 -0.001084 -0.055753  0.050219  0.124908   \n",
       "sms3   0.329047 -0.032793 -0.034566 -0.015802  0.052092  0.055648 -0.165269 -0.074037  0.061994 -0.107182  0.024422   \n",
       "sms4   0.002156  0.030817  0.038340  0.033888 -0.074634 -0.092604 -0.043691  0.061525 -0.045462  0.029576  0.029627   \n",
       "\n",
       "        topic11   topic12   topic13   topic14   topic15  \n",
       "sms0  -0.014893 -0.003493 -0.022887 -0.018399  0.048606  \n",
       "sms1   0.036879  0.039188 -0.011194  0.052755 -0.048924  \n",
       "sms2!  0.024711  0.025158 -0.044520 -0.023472  0.056638  \n",
       "sms3   0.023438  0.061472 -0.034343  0.029585 -0.067398  \n",
       "sms4  -0.007843  0.031439  0.005006 -0.091374 -0.010080  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n      <th>topic14</th>\n      <th>topic15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sms0</th>\n      <td>0.201169</td>\n      <td>0.002722</td>\n      <td>0.037228</td>\n      <td>0.010963</td>\n      <td>-0.019496</td>\n      <td>-0.053075</td>\n      <td>0.039710</td>\n      <td>-0.065104</td>\n      <td>0.011216</td>\n      <td>-0.081477</td>\n      <td>0.011095</td>\n      <td>-0.014893</td>\n      <td>-0.003493</td>\n      <td>-0.022887</td>\n      <td>-0.018399</td>\n      <td>0.048606</td>\n    </tr>\n    <tr>\n      <th>sms1</th>\n      <td>0.404380</td>\n      <td>-0.093877</td>\n      <td>-0.077510</td>\n      <td>0.050900</td>\n      <td>0.099974</td>\n      <td>0.047044</td>\n      <td>0.022954</td>\n      <td>0.065189</td>\n      <td>0.022957</td>\n      <td>-0.023891</td>\n      <td>-0.003125</td>\n      <td>0.036879</td>\n      <td>0.039188</td>\n      <td>-0.011194</td>\n      <td>0.052755</td>\n      <td>-0.048924</td>\n    </tr>\n    <tr>\n      <th>sms2!</th>\n      <td>-0.030458</td>\n      <td>-0.048076</td>\n      <td>0.090197</td>\n      <td>-0.067028</td>\n      <td>0.090846</td>\n      <td>-0.043121</td>\n      <td>-0.000488</td>\n      <td>-0.001084</td>\n      <td>-0.055753</td>\n      <td>0.050219</td>\n      <td>0.124908</td>\n      <td>0.024711</td>\n      <td>0.025158</td>\n      <td>-0.044520</td>\n      <td>-0.023472</td>\n      <td>0.056638</td>\n    </tr>\n    <tr>\n      <th>sms3</th>\n      <td>0.329047</td>\n      <td>-0.032793</td>\n      <td>-0.034566</td>\n      <td>-0.015802</td>\n      <td>0.052092</td>\n      <td>0.055648</td>\n      <td>-0.165269</td>\n      <td>-0.074037</td>\n      <td>0.061994</td>\n      <td>-0.107182</td>\n      <td>0.024422</td>\n      <td>0.023438</td>\n      <td>0.061472</td>\n      <td>-0.034343</td>\n      <td>0.029585</td>\n      <td>-0.067398</td>\n    </tr>\n    <tr>\n      <th>sms4</th>\n      <td>0.002156</td>\n      <td>0.030817</td>\n      <td>0.038340</td>\n      <td>0.033888</td>\n      <td>-0.074634</td>\n      <td>-0.092604</td>\n      <td>-0.043691</td>\n      <td>0.061525</td>\n      <td>-0.045462</td>\n      <td>0.029576</td>\n      <td>0.029627</td>\n      <td>-0.007843</td>\n      <td>0.031439</td>\n      <td>0.005006</td>\n      <td>-0.091374</td>\n      <td>-0.010080</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "pca_topic_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(pca_topic_vectors.values,sms.spam.values,test_size=0.2,random_state=271828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=1, tol=1e-05)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "lda=LDA(n_components=1,solver='svd',store_covariance=False,shrinkage=None,priors=None,tol=0.00001)\n",
    "lda.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9617768595041323"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "lda.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'准确率:0.96(+/-0.02)'"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "lda=LDA(n_components=1,solver='svd',store_covariance=False,shrinkage=None,priors=None,tol=0.00001)\n",
    "scores=cross_val_score(lda,pca_topic_vectors,sms.spam,cv=10)\n",
    "\"准确率:{:.2f}(+/-{:.2f})\".format(scores.mean(),scores.std()*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd=TruncatedSVD(n_components=16,n_iter=100)\n",
    "svd_topic_vectors=svd.fit_transform(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_topic_vectors=pd.DataFrame(svd_topic_vectors,columns=colums,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            topic0    topic1    topic2    topic3    topic4    topic5    topic6    topic7    topic8    topic9  \\\n",
       "sms0      0.117168  0.197241  0.001291  0.046938  0.029898  0.023255 -0.055717  0.066620 -0.079180 -0.070192   \n",
       "sms1      0.111082  0.420921 -0.088945  0.001267  0.005467 -0.095879  0.051561  0.034003  0.046031  0.015792   \n",
       "sms2!     0.116148 -0.047167 -0.052929  0.018714  0.101805 -0.074445 -0.045453  0.009717  0.021123 -0.026668   \n",
       "sms3      0.136377  0.342812 -0.030319 -0.003396  0.120083 -0.010570  0.033826 -0.118974 -0.100092 -0.033333   \n",
       "sms4      0.117986 -0.001852  0.029035  0.048743 -0.027100  0.067796 -0.097089 -0.042936  0.079900  0.006323   \n",
       "...            ...       ...       ...       ...       ...       ...       ...       ...       ...       ...   \n",
       "sms4832!  0.305045 -0.098430 -0.163711  0.043858  0.278112 -0.115736  0.072404 -0.049639 -0.038576 -0.011360   \n",
       "sms4833   0.122249  0.064666  0.077193 -0.034610  0.044142  0.041659  0.041438 -0.039057 -0.026100 -0.002505   \n",
       "sms4834   0.206329  0.099854  0.044925  0.041133 -0.005840 -0.014247 -0.010746 -0.020285 -0.002655 -0.092163   \n",
       "sms4835   0.168097 -0.023123  0.006503 -0.009782 -0.009180  0.061073 -0.105011 -0.028923  0.077440 -0.054957   \n",
       "sms4836   0.111025 -0.046968 -0.078988 -0.040812  0.016381  0.006019  0.009792  0.024452  0.014568 -0.046694   \n",
       "\n",
       "           topic10   topic11   topic12   topic13   topic14   topic15  \n",
       "sms0     -0.018184 -0.002791  0.007905  0.004756 -0.035671 -0.045036  \n",
       "sms1     -0.032491 -0.016574 -0.035084  0.043458 -0.022654  0.070904  \n",
       "sms2!     0.140838 -0.041963 -0.024075  0.028729 -0.012834 -0.067845  \n",
       "sms3     -0.069072 -0.081043 -0.028591  0.078012 -0.036653  0.073147  \n",
       "sms4      0.020471 -0.044011  0.001253  0.030746  0.054195 -0.029297  \n",
       "...            ...       ...       ...       ...       ...       ...  \n",
       "sms4832! -0.092641  0.063312 -0.015795  0.113507 -0.129220  0.117501  \n",
       "sms4833   0.211383  0.102310 -0.009561 -0.087287 -0.012005 -0.192491  \n",
       "sms4834  -0.057110  0.072065  0.097603 -0.005196  0.047922  0.016999  \n",
       "sms4835   0.073954  0.038780 -0.029359 -0.002064 -0.045830  0.045585  \n",
       "sms4836   0.043158 -0.034783 -0.002880  0.038250 -0.007603 -0.018951  \n",
       "\n",
       "[4837 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n      <th>topic14</th>\n      <th>topic15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sms0</th>\n      <td>0.117168</td>\n      <td>0.197241</td>\n      <td>0.001291</td>\n      <td>0.046938</td>\n      <td>0.029898</td>\n      <td>0.023255</td>\n      <td>-0.055717</td>\n      <td>0.066620</td>\n      <td>-0.079180</td>\n      <td>-0.070192</td>\n      <td>-0.018184</td>\n      <td>-0.002791</td>\n      <td>0.007905</td>\n      <td>0.004756</td>\n      <td>-0.035671</td>\n      <td>-0.045036</td>\n    </tr>\n    <tr>\n      <th>sms1</th>\n      <td>0.111082</td>\n      <td>0.420921</td>\n      <td>-0.088945</td>\n      <td>0.001267</td>\n      <td>0.005467</td>\n      <td>-0.095879</td>\n      <td>0.051561</td>\n      <td>0.034003</td>\n      <td>0.046031</td>\n      <td>0.015792</td>\n      <td>-0.032491</td>\n      <td>-0.016574</td>\n      <td>-0.035084</td>\n      <td>0.043458</td>\n      <td>-0.022654</td>\n      <td>0.070904</td>\n    </tr>\n    <tr>\n      <th>sms2!</th>\n      <td>0.116148</td>\n      <td>-0.047167</td>\n      <td>-0.052929</td>\n      <td>0.018714</td>\n      <td>0.101805</td>\n      <td>-0.074445</td>\n      <td>-0.045453</td>\n      <td>0.009717</td>\n      <td>0.021123</td>\n      <td>-0.026668</td>\n      <td>0.140838</td>\n      <td>-0.041963</td>\n      <td>-0.024075</td>\n      <td>0.028729</td>\n      <td>-0.012834</td>\n      <td>-0.067845</td>\n    </tr>\n    <tr>\n      <th>sms3</th>\n      <td>0.136377</td>\n      <td>0.342812</td>\n      <td>-0.030319</td>\n      <td>-0.003396</td>\n      <td>0.120083</td>\n      <td>-0.010570</td>\n      <td>0.033826</td>\n      <td>-0.118974</td>\n      <td>-0.100092</td>\n      <td>-0.033333</td>\n      <td>-0.069072</td>\n      <td>-0.081043</td>\n      <td>-0.028591</td>\n      <td>0.078012</td>\n      <td>-0.036653</td>\n      <td>0.073147</td>\n    </tr>\n    <tr>\n      <th>sms4</th>\n      <td>0.117986</td>\n      <td>-0.001852</td>\n      <td>0.029035</td>\n      <td>0.048743</td>\n      <td>-0.027100</td>\n      <td>0.067796</td>\n      <td>-0.097089</td>\n      <td>-0.042936</td>\n      <td>0.079900</td>\n      <td>0.006323</td>\n      <td>0.020471</td>\n      <td>-0.044011</td>\n      <td>0.001253</td>\n      <td>0.030746</td>\n      <td>0.054195</td>\n      <td>-0.029297</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>sms4832!</th>\n      <td>0.305045</td>\n      <td>-0.098430</td>\n      <td>-0.163711</td>\n      <td>0.043858</td>\n      <td>0.278112</td>\n      <td>-0.115736</td>\n      <td>0.072404</td>\n      <td>-0.049639</td>\n      <td>-0.038576</td>\n      <td>-0.011360</td>\n      <td>-0.092641</td>\n      <td>0.063312</td>\n      <td>-0.015795</td>\n      <td>0.113507</td>\n      <td>-0.129220</td>\n      <td>0.117501</td>\n    </tr>\n    <tr>\n      <th>sms4833</th>\n      <td>0.122249</td>\n      <td>0.064666</td>\n      <td>0.077193</td>\n      <td>-0.034610</td>\n      <td>0.044142</td>\n      <td>0.041659</td>\n      <td>0.041438</td>\n      <td>-0.039057</td>\n      <td>-0.026100</td>\n      <td>-0.002505</td>\n      <td>0.211383</td>\n      <td>0.102310</td>\n      <td>-0.009561</td>\n      <td>-0.087287</td>\n      <td>-0.012005</td>\n      <td>-0.192491</td>\n    </tr>\n    <tr>\n      <th>sms4834</th>\n      <td>0.206329</td>\n      <td>0.099854</td>\n      <td>0.044925</td>\n      <td>0.041133</td>\n      <td>-0.005840</td>\n      <td>-0.014247</td>\n      <td>-0.010746</td>\n      <td>-0.020285</td>\n      <td>-0.002655</td>\n      <td>-0.092163</td>\n      <td>-0.057110</td>\n      <td>0.072065</td>\n      <td>0.097603</td>\n      <td>-0.005196</td>\n      <td>0.047922</td>\n      <td>0.016999</td>\n    </tr>\n    <tr>\n      <th>sms4835</th>\n      <td>0.168097</td>\n      <td>-0.023123</td>\n      <td>0.006503</td>\n      <td>-0.009782</td>\n      <td>-0.009180</td>\n      <td>0.061073</td>\n      <td>-0.105011</td>\n      <td>-0.028923</td>\n      <td>0.077440</td>\n      <td>-0.054957</td>\n      <td>0.073954</td>\n      <td>0.038780</td>\n      <td>-0.029359</td>\n      <td>-0.002064</td>\n      <td>-0.045830</td>\n      <td>0.045585</td>\n    </tr>\n    <tr>\n      <th>sms4836</th>\n      <td>0.111025</td>\n      <td>-0.046968</td>\n      <td>-0.078988</td>\n      <td>-0.040812</td>\n      <td>0.016381</td>\n      <td>0.006019</td>\n      <td>0.009792</td>\n      <td>0.024452</td>\n      <td>0.014568</td>\n      <td>-0.046694</td>\n      <td>0.043158</td>\n      <td>-0.034783</td>\n      <td>-0.002880</td>\n      <td>0.038250</td>\n      <td>-0.007603</td>\n      <td>-0.018951</td>\n    </tr>\n  </tbody>\n</table>\n<p>4837 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "svd_topic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(svd_topic_vectors.values,sms.spam.values,test_size=0.2,random_state=271828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9638429752066116"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "lda=LDA(n_components=1,solver='svd',store_covariance=False,shrinkage=None,priors=None,tol=0.00001)\n",
    "lda.fit(x_train,y_train)\n",
    "lda.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'准确率:0.96(+/-0.02)'"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "lda=LDA(n_components=1,solver='svd',store_covariance=False,shrinkage=None,priors=None,tol=0.00001)\n",
    "scores=cross_val_score(lda,svd_topic_vectors,sms.spam,cv=10)\n",
    "\"准确率:{:.2f}(+/-{:.2f})\".format(scores.mean(),scores.std()*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}