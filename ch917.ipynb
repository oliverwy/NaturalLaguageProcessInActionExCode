{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=''\n",
    "for txt in gutenberg.fileids():\n",
    "    if 'shakespeare' in txt:\n",
    "        text+=gutenberg.raw(txt).lower()\n",
    "chars=sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices=dict((c,i) for i,c in enumerate(chars))\n",
    "indices_char=dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'语料库长度:375542，基本字符集长度：50'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\"语料库长度:{}，基本字符集长度：{}\".format(len(text),len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nb seq:375502\n"
     ]
    }
   ],
   "source": [
    "maxlen=40\n",
    "step=1\n",
    "sentences=[]\n",
    "next_chars=[]\n",
    "for i in range(0,len(text)-maxlen,step):\n",
    "    sentences.append(text[i:i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "print('nb seq:{}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['[the tragedie of julius caesar by willia', 'the tragedie of julius caesar by william', 'he tragedie of julius caesar by william ', 'e tragedie of julius caesar by william s', ' tragedie of julius caesar by william sh']\n['m', ' ', 's', 'h', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0:5])\n",
    "print(next_chars[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def onehot_encode_ger(sentence,char_indices,maxlen=40):\n",
    "    X=np.zeros((maxlen,len(char_indices.keys())))\n",
    "    for t,char in enumerate(sentence):\n",
    "        X[t,char_indices[char]]=1\n",
    "    return X\n",
    "    \n",
    "def onehot_encode_label(char,char_indices):\n",
    "    Y=np.zeros((len(char_indices)))\n",
    "    Y[char_indices[char]]=1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(datastore,next_char,char_indices,batchsize=32,maxlen=40):\n",
    "    X,Y=[],[]\n",
    "    while True:\n",
    "        for i in range(len(datastore)):\n",
    "            if (i % batchsize==0 and X and Y) or (i==len(datastore)):\n",
    "                X=np.reshape(X,(len(X),maxlen,len(char_indices)))\n",
    "                Y=np.reshape(Y,(len(Y),len(char_indices)))\n",
    "                yield X,Y\n",
    "                X,Y=[],[]\n",
    "            x=datastore[i]\n",
    "            y=next_chars[i]\n",
    "            x=onehot_encode_ger(x,char_indices,maxlen=maxlen)\n",
    "            y=onehot_encode_label(y,char_indices)   \n",
    "            X.append(x)\n",
    "            Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "m\n{'\\n': 0, ' ': 1, '!': 2, '&': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '9': 17, ':': 18, ';': 19, '?': 20, '[': 21, ']': 22, 'a': 23, 'b': 24, 'c': 25, 'd': 26, 'e': 27, 'f': 28, 'g': 29, 'h': 30, 'i': 31, 'j': 32, 'k': 33, 'l': 34, 'm': 35, 'n': 36, 'o': 37, 'p': 38, 'q': 39, 'r': 40, 's': 41, 't': 42, 'u': 43, 'v': 44, 'w': 45, 'x': 46, 'y': 47, 'z': 48, 'æ': 49}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print(next_chars[0])\n",
    "print(char_indices)\n",
    "onehot_encode_label(next_chars[0],char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=onehot_encode_ger(sentences[0],char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40, 50)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "sd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '&': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '9': 17, ':': 18, ';': 19, '?': 20, '[': 21, ']': 22, 'a': 23, 'b': 24, 'c': 25, 'd': 26, 'e': 27, 'f': 28, 'g': 29, 'h': 30, 'i': 31, 'j': 32, 'k': 33, 'l': 34, 'm': 35, 'n': 36, 'o': 37, 'p': 38, 'q': 39, 'r': 40, 's': 41, 't': 42, 'u': 43, 'v': 44, 'w': 45, 'x': 46, 'y': 47, 'z': 48, 'æ': 49}\n[0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 4.\n 1. 1. 1. 4. 1. 1. 1. 4. 1. 0. 3. 0. 0. 1. 0. 0. 2. 2. 2. 2. 0. 1. 0. 1.\n 0. 0.]\n[the tragedie of julius caesar by willia\n"
     ]
    }
   ],
   "source": [
    "print(char_indices)\n",
    "print(np.sum(sd,axis=0))\n",
    "print(sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru (GRU)                    (None, 128)               69120     \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\ndense (Dense)                (None, 50)                6450      \n_________________________________________________________________\nactivation (Activation)      (None, 50)                0         \n=================================================================\nTotal params: 75,570\nTrainable params: 75,570\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,LSTM,Dropout,GRU\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model=Sequential()\n",
    "model.add(GRU(128,input_shape=(maxlen,len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer=RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "第1次\n",
      "734/734 [==============================] - 8s 2ms/step - loss: 2.4404 - accuracy: 0.3100\n",
      "第2次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.9507 - accuracy: 0.4329\n",
      "第3次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.8564 - accuracy: 0.4587\n",
      "第4次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.8090 - accuracy: 0.4728\n",
      "第5次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.7868 - accuracy: 0.4805\n",
      "第6次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.7885 - accuracy: 0.4792\n",
      "第7次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.7952 - accuracy: 0.4774\n",
      "第8次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.8065 - accuracy: 0.4736\n",
      "第9次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.8267 - accuracy: 0.4670\n",
      "第10次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.8523 - accuracy: 0.4615\n",
      "第11次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.8819 - accuracy: 0.4526\n",
      "第12次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.9478 - accuracy: 0.4376\n",
      "第13次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.9540 - accuracy: 0.4323\n",
      "第14次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 1.9787 - accuracy: 0.4318\n",
      "第15次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.1827 - accuracy: 0.3828\n",
      "第16次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6148 - accuracy: 0.2758\n",
      "第17次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6979 - accuracy: 0.2470\n",
      "第18次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6968 - accuracy: 0.2460\n",
      "第19次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6703 - accuracy: 0.2528\n",
      "第20次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.7096 - accuracy: 0.2412\n",
      "第21次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.7075 - accuracy: 0.2487\n",
      "第22次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.7425 - accuracy: 0.2375\n",
      "第23次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8041 - accuracy: 0.2243\n",
      "第24次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.7717 - accuracy: 0.2318\n",
      "第25次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.7713 - accuracy: 0.2317\n",
      "第26次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8286 - accuracy: 0.2118\n",
      "第27次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8512 - accuracy: 0.2089\n",
      "第28次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8407 - accuracy: 0.2082\n",
      "第29次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8211 - accuracy: 0.2155\n",
      "第30次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8131 - accuracy: 0.2144\n",
      "第31次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8067 - accuracy: 0.2192\n",
      "第32次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8036 - accuracy: 0.2170\n",
      "第33次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.7880 - accuracy: 0.2258\n",
      "第34次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8255 - accuracy: 0.2154\n",
      "第35次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8484 - accuracy: 0.2096\n",
      "第36次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8282 - accuracy: 0.2143\n",
      "第37次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8285 - accuracy: 0.2124\n",
      "第38次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8693 - accuracy: 0.2069\n",
      "第39次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8450 - accuracy: 0.2150\n",
      "第40次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8223 - accuracy: 0.2207\n",
      "第41次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8164 - accuracy: 0.2260\n",
      "第42次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8363 - accuracy: 0.2171\n",
      "第43次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.9033 - accuracy: 0.1990\n",
      "第44次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8761 - accuracy: 0.2062\n",
      "第45次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8579 - accuracy: 0.2081\n",
      "第46次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8521 - accuracy: 0.2144\n",
      "第47次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8590 - accuracy: 0.2109\n",
      "第48次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8701 - accuracy: 0.2123\n",
      "第49次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.9195 - accuracy: 0.1995\n",
      "第50次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.9217 - accuracy: 0.1955\n",
      "第51次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8995 - accuracy: 0.2027\n",
      "第52次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8878 - accuracy: 0.2036\n",
      "第53次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.9328 - accuracy: 0.1952\n",
      "第54次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.9234 - accuracy: 0.1952\n",
      "第55次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.9255 - accuracy: 0.1932\n",
      "第56次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.9105 - accuracy: 0.1960\n",
      "第57次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8713 - accuracy: 0.2007\n",
      "第58次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8604 - accuracy: 0.2048\n",
      "第59次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8603 - accuracy: 0.2083\n",
      "第60次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8808 - accuracy: 0.2067\n",
      "第61次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.8131 - accuracy: 0.2195\n",
      "第62次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.7132 - accuracy: 0.2481\n",
      "第63次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6986 - accuracy: 0.2422\n",
      "第64次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.7075 - accuracy: 0.2443\n",
      "第65次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6753 - accuracy: 0.2465\n",
      "第66次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6356 - accuracy: 0.2567\n",
      "第67次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6237 - accuracy: 0.2603\n",
      "第68次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6502 - accuracy: 0.2538\n",
      "第69次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6932 - accuracy: 0.2405\n",
      "第70次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6923 - accuracy: 0.2465\n",
      "第71次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6426 - accuracy: 0.2568\n",
      "第72次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6152 - accuracy: 0.2605\n",
      "第73次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.5929 - accuracy: 0.2680\n",
      "第74次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.5776 - accuracy: 0.2659\n",
      "第75次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.5984 - accuracy: 0.2652\n",
      "第76次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.5992 - accuracy: 0.2658\n",
      "第77次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6158 - accuracy: 0.2612\n",
      "第78次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.6165 - accuracy: 0.2611\n",
      "第79次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.5945 - accuracy: 0.2656\n",
      "第80次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.5324 - accuracy: 0.2775\n",
      "第81次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.4905 - accuracy: 0.2916\n",
      "第82次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.4716 - accuracy: 0.2919\n",
      "第83次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.4576 - accuracy: 0.2994\n",
      "第84次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.4088 - accuracy: 0.3134\n",
      "第85次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.3902 - accuracy: 0.3186\n",
      "第86次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.3745 - accuracy: 0.3238\n",
      "第87次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.3691 - accuracy: 0.3230\n",
      "第88次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.3404 - accuracy: 0.3294\n",
      "第89次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.3155 - accuracy: 0.3373\n",
      "第90次\n",
      "734/734 [==============================] - 2s 2ms/step - loss: 2.3126 - accuracy: 0.3392\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "batch_size=512\n",
    "epochs=6\n",
    "model_structure=model.to_json()\n",
    "with open('smodel/shakes_lstm_model.json','w') as json_file:\n",
    "    json_file.write(model_structure)\n",
    "for i in range(90):\n",
    "    print('第{}次'.format(i+1))\n",
    "    history=model.fit(data_generator(sentences,next_chars,char_indices,batchsize=32,maxlen=40),steps_per_epoch=math.ceil(len(sentences)/batch_size),epochs=1)\n",
    "    model.save_weights('smodel/shakes_lstm_weight_{}.h5'.format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds=data_generator(sentences,next_chars,char_indices,batchsize=32,maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 1., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "next(sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sampple(preds,temperature=1.0):\n",
    "    preds=np.array(preds).astype('float64')\n",
    "    preds=np.log(preds)/temperature\n",
    "    exp_preds=np.exp(preds)\n",
    "    preds=exp_preds/np.sum(exp_preds)\n",
    "    probas=np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru_7 (GRU)                  (None, 128)               69120     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 50)                6450      \n_________________________________________________________________\nactivation_4 (Activation)    (None, 50)                0         \n=================================================================\nTotal params: 75,570\nTrainable params: 75,570\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "with open('smodel/shakes_lstm_model.json','r') as json_file:\n",
    "    j_s=json_file.read()\n",
    "modelX=model_from_json(j_s)\n",
    "modelX.summary()\n",
    "modelX.load_weights('smodel/shakes_lstm_weight_8.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "引入新奇度diversity:0.2\n",
      "生成文本的起点：and promise of their mettle:\n",
      "\n",
      "low march \n",
      "and promise of their mettle:\n",
      "\n",
      "low march man, and whe hast shoure and these these strome to send\n",
      "that sere this will will a man, and when,\n",
      "that man to selfe.\n",
      "that hast should not the sare to man, and were these these to selfe\n",
      "that a man to man to these world be and why say farth streses if is a man,\n",
      "that will seans inder these this the war,\n",
      "now these that i world and when the sere,\n",
      "these that will shake to see the sare these these these \n",
      "\n",
      "引入新奇度diversity:0.3\n",
      "生成文本的起点：and promise of their mettle:\n",
      "\n",
      "low march \n",
      "and promise of their mettle:\n",
      "\n",
      "low march so stire and what seake a then thise this geresting my stront and farth,\n",
      "and when these these share that will feare,\n",
      "that with should strenter the would caska, and should this this the man\n",
      "\n",
      "   cask. i would wor man, and whe his a these these these to sean,\n",
      "that as i will these that will man i warke,\n",
      "and whe sare a wart so strong a this these to man,\n",
      "what say fares, and when the sare be these shoul\n",
      "\n",
      "引入新奇度diversity:0.4\n",
      "生成文本的起点：and promise of their mettle:\n",
      "\n",
      "low march \n",
      "and promise of their mettle:\n",
      "\n",
      "low march to man, a war feare the sere,\n",
      "that be are to these that say see the speake i man\n",
      "\n",
      "   cask. i caska, who strowne this, i will man,\n",
      "and are to man: where these world a the fare,\n",
      "and the ware a walling will cassius a what a man,\n",
      "do i know he will these that man, and i fare\n",
      "eftering the sare these that i mart as to man\n",
      "to saw he sire these worll a the well farme,\n",
      "and he sare be thes sere to man to man\n",
      "\n",
      "引入新奇度diversity:0.5\n",
      "生成文本的起点：and promise of their mettle:\n",
      "\n",
      "low march \n",
      "and promise of their mettle:\n",
      "\n",
      "low march a waske, and when these stranter thes, i feare the strangie goes thisse thise should should when,\n",
      "thes man of the sar a walke a mee mance\n",
      "of man, of these strath selfe.\n",
      "buing the would shond are not senties these to the should\n",
      "\n",
      "   cassi. and be will man i thise mor speake in i ferauld fures these thus see\n",
      "\n",
      "   cassi. a soe to lay,\n",
      "and who would i saffe and fire these i will the these,\n",
      "why was world\n",
      "\n",
      "引入新奇度diversity:0.1\n",
      "生成文本的起点：and promise of their mettle:\n",
      "\n",
      "low march \n",
      "and promise of their mettle:\n",
      "\n",
      "low march selfe. and whe haue these these these these strange these these these these these these these these these this man\n",
      "\n",
      "   cask. i will the sawe that will will man,\n",
      "i will man i will these these these these these these these these these these these these these these these these these these these these these these these these these these these these these these these these these these these these these\n",
      "\n",
      "引入新奇度diversity:0.6\n",
      "生成文本的起点：and promise of their mettle:\n",
      "\n",
      "low march \n",
      "and promise of their mettle:\n",
      "\n",
      "low march to see tie these should the peare caska,\n",
      "and wht and feror see to tell will caska,\n",
      "and a will ablid. for for worse all this,\n",
      "thas lind this that there these i fares of this no peare,\n",
      "that strange the world these to man i will:\n",
      "for worse wor when the sooe the sar with spake of of battrie.\n",
      "but sere the sar gantsies strande  some.\n",
      "\n",
      "th those that i spalke of the theare then,\n",
      "cassius be as to grast is \n",
      "\n",
      "引入新奇度diversity:1.0\n",
      "生成文本的起点：and promise of their mettle:\n",
      "\n",
      "low march \n",
      "and promise of their mettle:\n",
      "\n",
      "low march as li:fid: rest but strowne,\n",
      "hand all, and gaining whost farght leret forme fast.\n",
      "thri'd, a thind as and faresar now on will bmen\n",
      "to poerire tis al has good:\n",
      "but indes regarres bid sein seet bing willing do\n",
      "epindt i with singes ind:\n",
      "bo ser with for firemforerie warke you would,\n",
      "but it will wer thinger tree from\n",
      "thisas wlane wist nights,\n",
      "has doghtransinie thond when will yem: thnindest,\n",
      "bises niser\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "start_index=random.randint(0,len(text)-maxlen-1)\n",
    "for diversity in [0.2,0.3,0.4,0.5,0.1,0.6,1.0]:\n",
    "    print()\n",
    "    print('引入新奇度diversity:{}'.format(diversity))\n",
    "    generated=''\n",
    "    sentences=text[start_index:start_index+maxlen]\n",
    "    generated+=sentences\n",
    "    print('生成文本的起点：{}'.format(generated))\n",
    "    sys.stdout.write(generated)\n",
    "    for i in range(400):\n",
    "        x=np.zeros((1,maxlen,len(chars)))\n",
    "        for t,char in enumerate(sentences):\n",
    "            x[0,t,char_indices[char]]=1\n",
    "        preds=modelX.predict(x,verbose=0)[0]\n",
    "        next_index=sampple(preds,temperature=diversity)\n",
    "        next_char=indices_char[next_index]\n",
    "        generated+=next_char\n",
    "        sentences=sentences[1:]+next_char\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index=random.randint(0,len(text)-maxlen-1)\n",
    "sentences=text[start_index:start_index+maxlen]\n",
    "x=np.zeros((1,maxlen,len(chars)))\n",
    "for t,char in enumerate(sentences):\n",
    "    x[0,t,char_indices[char]]=1\n",
    "preds=modelX.predict(x,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.3380340e-02, 2.4428939e-02, 3.0075779e-15, 4.4806177e-12,\n",
       "       7.4759722e-03, 1.8878028e-08, 2.4904981e-08, 5.8379300e-02,\n",
       "       3.5610752e-05, 2.9412573e-02, 2.2766442e-18, 1.6471226e-17,\n",
       "       2.2499488e-18, 2.1927373e-18, 2.2913865e-18, 6.5899006e-18,\n",
       "       2.3156388e-18, 7.7540266e-18, 5.3861374e-03, 6.5950776e-04,\n",
       "       3.6670347e-03, 2.2857991e-18, 9.1086358e-18, 1.3988922e-02,\n",
       "       5.6121605e-03, 6.7085579e-02, 1.0153474e-02, 1.7607534e-01,\n",
       "       1.5715145e-03, 5.7660630e-03, 1.1308195e-02, 5.5813767e-02,\n",
       "       2.3330172e-18, 2.0412235e-02, 1.0090580e-01, 1.9799618e-02,\n",
       "       5.0031878e-03, 2.4540836e-02, 1.2248082e-02, 1.0890204e-05,\n",
       "       1.1204369e-02, 1.4168358e-01, 1.2137576e-01, 3.2445908e-02,\n",
       "       2.3286061e-04, 1.1044219e-02, 3.7534028e-06, 8.8883732e-03,\n",
       "       1.7463359e-11, 2.1341638e-16], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "preds=preds[0]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=np.array(preds).astype('float64')\n",
    "    # preds=np.array(preds).astype('float64')\n",
    "    # preds=np.log(preds)/temperature\n",
    "    # exp_preds=np.exp(preds)\n",
    "    # preds=exp_preds/np.sum(exp_preds)\n",
    "    # probas=np.random.multinomial(1,preds,1)\n",
    "    # return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.33803403e-02, 2.44289394e-02, 3.00757789e-15, 4.48061770e-12,\n",
       "       7.47597218e-03, 1.88780280e-08, 2.49049812e-08, 5.83792999e-02,\n",
       "       3.56107521e-05, 2.94125732e-02, 2.27664424e-18, 1.64712257e-17,\n",
       "       2.24994884e-18, 2.19273731e-18, 2.29138646e-18, 6.58990061e-18,\n",
       "       2.31563877e-18, 7.75402663e-18, 5.38613740e-03, 6.59507758e-04,\n",
       "       3.66703467e-03, 2.28579906e-18, 9.10863580e-18, 1.39889224e-02,\n",
       "       5.61216054e-03, 6.70855790e-02, 1.01534743e-02, 1.76075339e-01,\n",
       "       1.57151453e-03, 5.76606300e-03, 1.13081951e-02, 5.58137670e-02,\n",
       "       2.33301722e-18, 2.04122346e-02, 1.00905798e-01, 1.97996181e-02,\n",
       "       5.00318781e-03, 2.45408360e-02, 1.22480821e-02, 1.08902041e-05,\n",
       "       1.12043694e-02, 1.41683578e-01, 1.21375762e-01, 3.24459076e-02,\n",
       "       2.32860606e-04, 1.10442191e-02, 3.75340278e-06, 8.88837315e-03,\n",
       "       1.74633589e-11, 2.13416383e-16])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ -21.56984396,  -18.55993403, -167.18820665, -130.656301  ,\n",
       "        -24.48030556,  -88.92633565,  -87.54099003,  -14.20396953,\n",
       "        -51.2143147 ,  -17.63166518, -203.11914571, -193.22458357,\n",
       "       -203.17812097, -203.30690499, -203.086873  , -197.80496703,\n",
       "       -203.03423049, -196.991597  ,  -26.11963387,  -36.62008412,\n",
       "        -28.04185967, -203.09908007, -196.18654361,  -21.34744762,\n",
       "        -25.91409755,  -13.50893088,  -22.94969669,   -8.68421656,\n",
       "        -32.27857729,  -25.77882877,  -22.41113794,  -14.4286736 ,\n",
       "       -202.99684651,  -19.45810412,  -11.46783943,  -19.61046316,\n",
       "        -26.48840004,  -18.53708387,  -22.01192959,  -57.13823441,\n",
       "        -22.45725727,   -9.77079514,  -10.54432037,  -17.14090479,\n",
       "        -41.8253527 ,  -22.52924072,  -62.46423861,  -23.61505622,\n",
       "       -123.85458104, -180.41643283])"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "preds=np.log(preds)/0.2\n",
    "preds\n",
    "    # preds=np.array(preds).astype('float64')\n",
    "    # preds=np.log(preds)/temperature\n",
    "    # exp_preds=np.exp(preds)\n",
    "    # preds=exp_preds/np.sum(exp_preds)\n",
    "    # probas=np.random.multinomial(1,preds,1)\n",
    "    # return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4.28880000e-10, 8.70007637e-09, 2.46084587e-73, 1.80588234e-57,\n",
       "       2.33527689e-11, 2.39763535e-39, 9.58144675e-39, 6.78101046e-07,\n",
       "       5.72671711e-23, 2.20122839e-08, 6.11611794e-89, 1.21235439e-84,\n",
       "       5.76584840e-89, 5.06912536e-89, 6.31672120e-89, 1.24278020e-86,\n",
       "       6.65815748e-89, 2.80308612e-86, 4.53301485e-12, 1.24766945e-16,\n",
       "       6.63093976e-13, 6.24008129e-89, 6.26998769e-86, 5.35699570e-10,\n",
       "       5.56737444e-12, 1.35876973e-06, 1.07912901e-10, 1.69235968e-04,\n",
       "       9.58499742e-15, 6.37377774e-12, 1.84912580e-10, 5.41634945e-07,\n",
       "       6.91177700e-89, 3.54366578e-09, 1.04611786e-05, 3.04287465e-09,\n",
       "       3.13497460e-12, 8.90116323e-09, 2.75638858e-10, 1.53172249e-25,\n",
       "       1.76578201e-10, 5.70949355e-05, 2.63426733e-05, 3.59583400e-08,\n",
       "       6.84668137e-19, 1.64314192e-10, 7.44947825e-28, 5.54767990e-11,\n",
       "       1.62419772e-54, 4.42729823e-79])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "exp_preds=np.exp(preds)\n",
    "exp_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.61355985e-06, 3.27319854e-05, 9.25835220e-70, 6.79420637e-54,\n",
       "       8.78592852e-08, 9.02053751e-36, 3.60479336e-35, 2.55119525e-03,\n",
       "       2.15454224e-19, 8.28160265e-05, 2.30104512e-85, 4.56119744e-81,\n",
       "       2.16926447e-85, 1.90713886e-85, 2.37651737e-85, 4.67566737e-83,\n",
       "       2.50497471e-85, 1.05459504e-82, 1.70543992e-08, 4.69406204e-13,\n",
       "       2.49473469e-09, 2.34768341e-85, 2.35893499e-82, 2.01544328e-06,\n",
       "       2.09459332e-08, 5.11205064e-03, 4.05996837e-07, 6.36710415e-01,\n",
       "       3.60612921e-11, 2.39798355e-08, 6.95689969e-07, 2.03777373e-03,\n",
       "       2.60039308e-85, 1.33322067e-05, 3.93577170e-02, 1.14480982e-05,\n",
       "       1.17946025e-08, 3.34885273e-05, 1.03702619e-06, 5.76274461e-22,\n",
       "       6.64333834e-07, 2.14806229e-01, 9.91080953e-02, 1.35284773e-04,\n",
       "       2.57590238e-15, 6.18193394e-07, 2.80269049e-24, 2.08718372e-07,\n",
       "       6.11066084e-51, 1.66566654e-75])"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "preds=exp_preds/np.sum(exp_preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "probas=np.random.multinomial(1,preds,1)\n",
    "np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}